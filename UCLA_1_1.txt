nohup: ignoring input
pretrain?: False
hidden_size: 256
n_heads: 8
num_layers: 4
batch_size: 4
==================================================
[INFO] Starting NW-UCLA dataset processing on cuda...
==================================================
[INFO]: proability of dropping regularization: 0.0
[INFO]: data being repeated by 10 times
Collected 10200 sequences for train + val.
Each sequence shape: torch.Size([3, 64, 20, 1])
Collected 464 sequences for test.
Each sequence shape: torch.Size([3, 64, 20, 1])
[INFO] Number of classes: 10
====================================================================================================
====================================================================================================
====================================================================================================
====================================================================================================
pretrained model loaded successfully!
[INFO] finetuning the entire T1 model...
is T1 freezed? False
unfreezing layers: None
  0%|          | 0/100 [00:00<?, ?it/s]/home/peng.1007/BPMT/baseline/action_recognition/cascadeformer_1_1/joint/n_ucla/base_dataset.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  seq   = torch.tensor(self.seqs[idx],   dtype=torch.float32)
  1%|          | 1/100 [00:58<1:36:08, 58.27s/it]  2%|▏         | 2/100 [01:55<1:34:35, 57.91s/it]  3%|▎         | 3/100 [02:50<1:31:08, 56.38s/it]  4%|▍         | 4/100 [03:45<1:29:16, 55.80s/it]  5%|▌         | 5/100 [04:39<1:27:33, 55.29s/it]  6%|▌         | 6/100 [05:34<1:26:13, 55.03s/it]  7%|▋         | 7/100 [06:30<1:25:40, 55.28s/it]  8%|▊         | 8/100 [07:25<1:24:50, 55.33s/it]  9%|▉         | 9/100 [08:22<1:24:34, 55.76s/it] 10%|█         | 10/100 [09:18<1:23:52, 55.92s/it] 11%|█         | 11/100 [10:15<1:23:35, 56.35s/it] 12%|█▏        | 12/100 [11:11<1:22:27, 56.22s/it] 13%|█▎        | 13/100 [12:07<1:21:21, 56.11s/it] 14%|█▍        | 14/100 [13:05<1:21:01, 56.53s/it] 15%|█▌        | 15/100 [14:02<1:20:17, 56.68s/it] 16%|█▌        | 16/100 [14:57<1:18:43, 56.23s/it] 17%|█▋        | 17/100 [15:53<1:17:37, 56.12s/it] 18%|█▊        | 18/100 [16:49<1:16:35, 56.04s/it] 19%|█▉        | 19/100 [17:44<1:15:36, 56.01s/it] 20%|██        | 20/100 [18:39<1:14:15, 55.70s/it] 21%|██        | 21/100 [19:36<1:13:33, 55.86s/it] 22%|██▏       | 22/100 [20:32<1:12:57, 56.12s/it] 23%|██▎       | 23/100 [21:27<1:11:28, 55.69s/it] 24%|██▍       | 24/100 [22:22<1:10:20, 55.53s/it] 25%|██▌       | 25/100 [23:17<1:08:55, 55.14s/it] 26%|██▌       | 26/100 [24:11<1:07:46, 54.95s/it] 27%|██▋       | 27/100 [25:07<1:07:03, 55.12s/it] 28%|██▊       | 28/100 [26:01<1:05:55, 54.94s/it] 29%|██▉       | 29/100 [26:56<1:05:10, 55.08s/it] 30%|███       | 30/100 [27:52<1:04:18, 55.12s/it] 31%|███       | 31/100 [28:48<1:03:40, 55.38s/it]